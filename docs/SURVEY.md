# 🔎 B / C / D 服務行為調查問卷

請各服務負責人填寫，幫助我們釐清 B / C / D 的基礎運作方式。  
在選項打勾或填空即可。  

---

## 1. 執行模型
- [ ] 單線程 / 單進程  
- [ ] 多線程 / 多進程  
- [ ] 其他：___________  

## 2. 連線管理
- [ ] 每次請求都新建一條連線（短連線）  
- [ ] 可以重用既有連線（HTTP keep-alive / HTTP/2 multiplexing / gRPC channel）  
- [ ] 不確定 → 請描述：___________  

## 3. 請求併發能力
- [ ] 僅能處理 1 個（例如單一 semaphore）  
- [ ] 可以同時處理 N 個（N = ________）  
- [ ] 沒有明確限制，取決於 OS / 資源  
- [ ] 其他：___________  

## 4. 排隊行為
- [ ] 直接被拒絕（立即回 busy / 429 / RESOURCE_EXHAUSTED）  
- [ ] 進入排隊等待（最大佇列長度 = ________）  
- [ ] 不確定 → 請描述：___________  

## 5. Timeout 設定
- Connect timeout = ________ ms  
- Request / Process timeout = ________ ms  

## 6. Retry 行為
- 會重試的情況：________________________  
- 最大重試次數：___________  
- 是否會換不同 instance？ [ ] Yes / [ ] No  
- 不會重試的情況：________________________  

---

# 📑 Appendix — 問題解釋

### Q1. 執行模型
👉 想知道：服務是單線程還是多線程/多進程？  
- **單線程 / 單進程** → 通常依靠 async event loop 提供併發。  
- **多線程 / 多進程** → 能並行利用多核心。  
**意義**：決定了基礎的併發與資源利用方式。

---

### Q2. 連線管理
👉 想知道：一個請求進來，需不需要新開一條 TCP 連線？  
- **每次新建連線（短連線）** → 成本高，建立/釋放延遲大。  
- **可重用連線（長連線）** → 效率高，可在一條連線上處理多個請求（HTTP keep-alive、HTTP/2 multiplexing、gRPC channel）。  
**意義**：這是傳輸層的行為，會影響吞吐量、延遲，以及 timeout 應該怎麼設。

---

### Q3. 請求併發能力
👉 想知道：伺服器一次能處理多少「請求」？  
- **單請求** → 例如 C：雖然能接受很多連線，但因為設了 `Semaphore(1)`，同一時間只會處理 1 個請求。  
- **多請求** → 例如 B、D：用 async event loop 或 thread pool，可同時處理多個請求。  
**意義**：這是應用層的 concurrency 限制，跟「能接受多少連線」不同。  
- 要分清楚「能接幾個連線」和「能同時跑幾個請求」。

---

### Q4. 排隊行為
👉 想知道：如果請求來的比伺服器能處理的多，會怎麼辦？  
- **直接拒絕** → 如 C 現在的模式（忙就回 `RESOURCE_EXHAUSTED`），沒有排隊。  
- **放進隊列** → 常見於 thread pool / worker pool，排隊長度超過上限才拒絕。  
**意義**：這是負載管理策略，決定超載時是「立即拒絕」還是「等待」。  
- 沒有排隊 → 保持低延遲，但錯誤率會升高。  
- 有排隊 → 可以消化高峰，但會導致長尾延遲上升（p95/p99 變差）。

---

### Q5. Timeout 設定
👉 想知道：這個服務在 **建立連線** 與 **處理請求** 各自的 timeout 值。  
- **Connect timeout** → 小而果斷（100–400ms 常見）。  
- **Process timeout** → 取決於 p95–p99 延遲，並且要比上游的 E2E 截止短。  
**意義**：若 timeout 值設錯，會導致「白等」或「誤殺正常尾部請求」。

---

### Q6. Retry 行為
👉 想知道：服務遇到錯誤時會不會自動重試？  
- **正確做法** → 只在 **connect fail**（還沒送出請求）時重試 1 次，並且要換 instance。  
- **錯誤做法** → 在 timeout 或 busy 時重試，會造成 **retry storm**。  
**意義**：釐清 retry 政策，才能設計正確的 backoff / retry budget，避免放大下游壓力。

---

### 🎯 總結
- **Q2 連線管理** = 傳輸層 → 「要不要重複建立連線？」  
- **Q3 請求併發** = 應用層 → 「同一時間能處理幾個請求？」  
- **Q4 排隊行為** = 負載策略 → 「超過併發能力時，丟掉還是排隊？」  
- **Q5 Timeout** = 時間邊界 → 「多久要放棄？」  
- **Q6 Retry** = 重試策略 → 「什麼情況下可以再送一次？」  

這六個問題合起來，才能完整描述一個服務的行為：  
- 能不能重用連線？  
- 能同時跑多少請求？  
- 超過容量會怎麼處理？  
- Timeout 設在哪裡？  
- Retry 怎麼做？  
